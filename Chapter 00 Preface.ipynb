{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas Cookbook  \n",
    "\n",
    "## Recipes for Scientific Computing, Time Series Analysis and Data Visualization using Python\n",
    "\n",
    "Theodore Petrou"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preface\n",
    "\n",
    "The popularity of data science has skyrocketed since it was called The Sexiest Job of the 21st Century by the Harvard Review in 2012. It was ranked as the number one job by Glassdoor in both 2016 and 2017. Fueling this skyrocketing popularity for data science is the demand from industry. Several applications have made big splashes in the news, such as Netflix making better movie recommendations, IBM Watson defeating humans at Jeopardy, Tesla building self-driving cars, Major League Baseball teams finding undervalued prospects, and Google learning to identify cats on the internet.\n",
    "\n",
    "Nearly every industry is finding ways to use data science to build new technology or provide deeper insights. Due to such noteworthy successes, an ever-present aura of hype seems to encapsulate data science. Most of the scientific progress backing this hype stems from the field of machine learning, which produces the algorithms that make the predictions responsible for artificial intelligence.\n",
    "\n",
    "The fundamental building block for all machine learning algorithms is, of course, data. As companies have realized this, there is no shortage of it. The business intelligence company, Domo, estimates that 90% of the world's data has been created in just the last two years. Although machine learning gets all the attention, it is completely reliant on the quality of the data that it is fed. Before data ever reaches the input layers of a machine learning algorithm, it must be prepared, and for data to be prepared properly, it needs to be explored thoroughly for basic understanding and to identify inaccuracies. Before data can be explored, it needs to be captured.\n",
    "\n",
    "\n",
    "2012年にハーバード・レビューで「The Sexiest Job of the 21st Century」と呼ばれて以来、データサイエンスの人気は急上昇しています。また、2016年と2017年にはGlassdoorの調査でナンバーワンの仕事にランクインしています。データサイエンスの人気が急上昇している背景には、産業界からの需要があります。Netflixがより良い映画の推薦をしたり、IBM WatsonがJeopardyで人間を破ったり、Teslaが自動運転車を作ったり、メジャーリーグのチームが過小評価されている見込み客を見つけたり、Googleがインターネット上で猫を識別するために学習したりと、いくつかのアプリケーションがニュースで大きな話題を呼んでいます。\n",
    "\n",
    "ほぼすべての業界で、データサイエンスを使って新しい技術を構築したり、より深い洞察を提供したりする方法が見出されています。このような注目すべき成功のために、データサイエンスを包み込むような誇大なオーラが常に漂っているように見えます。この誇大広告を裏付ける科学的進歩のほとんどは機械学習の分野に由来しています。\n",
    "\n",
    "すべての機械学習アルゴリズムの基本的な構成要素は、もちろんデータである。企業がこのことに気付いたように、データには事欠かない。ビジネスインテリジェンス企業のDomoは、この2年間だけで世界のデータの90％が作成されたと推定している。機械学習が注目を集めていますが、それはデータの質に完全に依存しています。データが機械学習アルゴリズムの入力層に到達する前に、データを準備しなければならず、データが適切に準備されるためには、基本的な理解と不正確さを識別するためにデータを徹底的に探索する必要があります。データが探索される前に、データを捕捉する必要があります。\n",
    "\n",
    "To summarize, we can cast the data science pipeline into three stages--data capturing, data exploration, and machine learning. There are a vast array of tools available to complete each stage of the pipeline. Pandas is the dominant tool in the scientific Python ecosystem for data exploration and analysis. It is tremendously capable of inspecting, cleaning, tidying, filtering, transforming, aggregating, and even visualizing (with some help) all types of data. It is not a tool for initially capturing the data, nor is it a tool to build machine learning models.\n",
    "\n",
    "For many data analysts and scientists who use Python, the vast majority of their work will be done using pandas. This is likely because the initial data exploration and preparation tend to take the most time. Some entire projects consist only of data exploration and have no machine learning component. Data scientists spend so much time on this stage that a timeless lore has arisen--Data scientists spend 80% of their time cleaning the data and the other 20% complaining about cleaning the data.\n",
    "\n",
    "要約すると、データサイエンスのパイプラインは、データ収集、データ探査、機械学習の3つの段階に分けることができます。パイプラインの各段階を完了させるために利用可能なツールは膨大な数にのぼります。Pandasは科学的なPythonのエコシステムにおいて、データの探索と分析のための支配的なツールです。検査、クリーニング、整理整頓、フィルタリング、変換、集計、さらにはあらゆるタイプのデータを可視化することができます（多少の助けはありますが）。データを最初に取得するためのツールではなく、機械学習モデルを構築するためのツールでもありません。\n",
    "\n",
    "Pythonを使っている多くのデータアナリストや科学者にとって、仕事の大部分はpandasを使って行われます。これは、初期データの探索と準備に最も時間がかかる傾向があるからでしょう。プロジェクト全体がデータ探査のみで構成され、機械学習の要素を持たないものもあります。データサイエンティストはこの段階に非常に多くの時間を費やしているため、時代を超えた言い伝えが生まれている--データサイエンティストは80%の時間をデータのクリーニングに費やし、残りの20%はデータのクリーニングに文句を言っている。\n",
    "\n",
    "Although there is an abundance of open source and free programming languages available to do data exploration, the field is currently dominated by just two players, Python and R. The two languages have vastly different syntax but are both very capable of doing data analysis and machine learning. One measure of popularity is the number of questions asked on the popular Q&A site, Stack Overflow (https://insights.stackoverflow.com/trends):\n",
    "\n",
    "While this is not a true measure of usage, it is clear that both Python and R have become increasingly popular, likely due to their data science capabilities. It is interesting to note that the percentage of Python questions remained constant until the year 2012, when data science took off. What is probably most astonishing about this graph is that pandas questions now make up a whopping one percent of all the newest questions on Stack Overflow.\n",
    "\n",
    "One of the reasons why Python has become a language of choice for data science is that it is a fairly easy language to learn and develop, and so it has a low barrier to entry. It is also free and open source, able to run on a variety of hardware and software, and a breeze to get up and running. It has a very large and active community with a substantial amount of free resources online. In my opinion, Python is one of the most fun languages to develop programs with. The syntax is so clear, concise, and intuitive but like all languages, takes quite a long time to master.\n",
    "\n",
    "データ探索を行うためのオープンソースやフリーのプログラミング言語は豊富にありますが、この分野は現在、PythonとRという2つの言語に支配されています。人気の指標の一つとして、人気のあるQ&Aサイト「Stack Overflow」（https://insights.stackoverflow.com/trends）での質問数が挙げられます。\n",
    "\n",
    "これは本当の意味での利用状況を測るものではありませんが、PythonとRの両方の人気が高まっていることは明らかで、おそらくデータサイエンスの機能があるからだと思われます。興味深いのは、Pythonの質問の割合がデータサイエンスが流行した2012年まで一定であったことです。このグラフでおそらく最も驚くべきことは、Pandasの質問がStack Overflowの最新の質問の1%を占めるようになったことです。\n",
    "\n",
    "Pythonがデータサイエンスのための言語として選ばれるようになった理由の1つは、Pythonが学習や開発がかなり簡単な言語であるため、参入障壁が低いということです。また、フリーでオープンソースであり、様々なハードウェアやソフトウェア上で動作し、立ち上げるのも簡単です。Pythonには、オンライン上のかなりの量の無料のリソースがあり、非常に大規模で活発なコミュニティがあります。私の考えでは、Pythonはプログラムを開発するのが最も楽しい言語の一つです。構文はとても明確で、簡潔で、直感的ですが、他の言語と同じように、マスターするのにはかなり長い時間がかかります。\n",
    "\n",
    "As Python was not built for data analysis like R, the syntax may not come as naturally as it does for some other Python libraries. This actually might be part of the reason why there are so many Stack Overflow questions on it. Despite its tremendous capabilities, pandas code can often be poorly written. One of the main aims of this book is to show performant and idiomatic pandas code.\n",
    "\n",
    "For all its greatness, Stack Overflow, unfortunately perpetuates misinformation and is a source for lots of poorly written pandas. This is actually not the fault of Stack Overflow or its community. Pandas is an open source project and has had numerous major changes, even recently, as it approaches its tenth year of existence in 2018. The upside of open source, though, is that new features get added to it all the time.\n",
    "\n",
    "The recipes in this book were formulated through my experience working as a data scientist, building and hosting several week-long data exploration bootcamps, answering several hundred questions on Stack Overflow, and building tutorials for my local meetup group. The recipes not only offer idiomatic solutions to common data problems, but also take you on journeys through many real-world datasets, where surprising insights are often discovered. These recipes will also help you master the pandas library, which will give you a gigantic boost in productivity. There is a huge difference between those who have only cursory knowledge of pandas and those who have it mastered. There are so many interesting and fun tricks to solve your data problems that only become apparent if you truly know the library inside and out. Personally, I find pandas to be a delightful and fun tool to analyze data with, and I hope you enjoy your journey along with me. If you have questions, please feel free to reach out to me on Twitter: @TedPetrou.\n",
    "\n",
    "PythonはRのようにデータ分析のために作られたわけではないので、他のPythonライブラリのように自然な構文にはならないかもしれません。これが、Stack Overflowで質問が多い理由の一部かもしれません。驚異的な機能を持っているにもかかわらず、pandasのコードはしばしば貧弱な書き方になることがあります。この本の主な目的の一つは、パフォーマンスの高いイディオムなpandasのコードを示すことです。\n",
    "\n",
    "Stack Overflowはその偉大さの割には、残念ながら誤った情報を広めており、稚拙に書かれたパンダのソースになっています。これは実は Stack Overflow やそのコミュニティのせいではありません。パンダはオープンソースプロジェクトであり、2018年で10年目を迎えようとしている最近でも、数々の大きな変更が行われてきました。しかし、オープンソースの長所は、常に新しい機能が追加されていることです。\n",
    "\n",
    "本書のレシピは、データサイエンティストとして働いていた私の経験、1週間のデータ探査ブートキャンプをいくつか構築して主催したこと、Stack Overflowで数百の質問に答えたこと、地元のミートアップグループのためにチュートリアルを構築したことなどから定式化されたものです。このレシピは、一般的なデータの問題に対する慣用的な解決策を提供するだけでなく、実際のデータセットの中を旅してみると、驚くべき洞察が発見されることもしばしばあります。これらのレシピは、あなたがパンダライブラリをマスターするのにも役立ち、生産性を飛躍的に向上させてくれます。パンダの知識がざっとしかない人と、それをマスターしている人の間には大きな違いがあります。データの問題を解決するための、とても面白くて楽しいトリックがたくさんあるのですが、それは本当にパンダスライブラリを知っている人にしかわからないことです。個人的には、パンダはデータを分析するための楽しくて楽しいツールだと思っています。ご質問があれば、Twitterでお気軽にお問い合わせください。TedPetrou.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What this book covers\n",
    "\n",
    "Chapter 1, Pandas Foundations, covers the anatomy and vocabulary used to identify the components of the two main pandas data structures, the Series and the DataFrame. Each column must have exactly one type of data, and each of these data types is covered. You will learn how to unleash the power of the Series and the DataFrame by calling and chaining together their methods.\n",
    "\n",
    "Chapter 2, Essential DataFrame Operations, focuses on the most crucial and common operations that you will perform during data analysis.\n",
    "\n",
    "Chapter 3, Beginning Data Analysis, helps you develop a routine to get started after reading in your data. Other interesting discoveries will be made.\n",
    "\n",
    "Chapter 4, Selecting Subsets of Data, covers the many varied and potentially confusing ways of selecting different subsets of data.\n",
    "\n",
    "Chapter 5, Boolean Indexing, covers the process of querying your data to select subsets of it based on Boolean conditions.\n",
    "\n",
    "Chapter 6, Index Alignment, targets the very important and often misunderstood index object. Misuse of the Index is responsible for lots of erroneous results, and these recipes show you how to use it correctly to deliver powerful results.\n",
    "\n",
    "Chapter 7, Grouping for Aggregation, Filtration, and Transformation, covers the powerful grouping capabilities that are almost always necessary during a data analysis. You will build customized functions to apply to your groups.\n",
    "\n",
    "Chapter 8, Restructuring Data into Tidy Form, explains what tidy data is and why it’s so important, and then it shows you how to transform many different forms of messy datasets into tidy ones.\n",
    "\n",
    "Chapter 9, Combining Pandas Objects, covers the many available methods to combine DataFrames and Series vertically or horizontally. We will also do some web-scraping to compare President Trump's and Obama's approval rating and connect to an SQL relational database.\n",
    "\n",
    "Chapter 10, Time Series Analysis, covers advanced and powerful time series capabilities to dissect by any dimension of time possible.\n",
    "\n",
    "Chapter 11, Visualization with Matplotlib, Pandas, and Seaborn, introduces the matplotlib library, which is responsible for all of the plotting in pandas. We will then shift focus to the pandas plot method and, finally, to the seaborn library, which is capable of producing aesthetically pleasing visualizations not directly available in pandas.\n",
    "\n",
    "第1章「Pandasの基礎」では、2つの主要なパンダのデータ構造であるSeriesとDataFrameの構成要素を識別するために使用される解剖学と語彙をカバーしています。各列は正確に1つのデータタイプを持つ必要があり、これらのデータタイプのそれぞれがカバーされています。SeriesとDataFrameのメソッドを呼び出したり、チェーニングしたりすることで、SeriesとDataFrameのパワーを最大限に引き出す方法を学びます。\n",
    "\n",
    "第2章「DataFrame の基本操作」では、データ分析中に実行する最も重要で一般的な操作に焦点を当てています。\n",
    "\n",
    "第3章「データ分析を始める」では、データを読み込んだ後に始めるためのルーチンを開発するのに役立ちます。その他にも興味深い発見があるでしょう。\n",
    "\n",
    "第4章、データのサブセットの選択では、データのさまざまなサブセットを選択するための多くの多様で混乱を招く可能性のある方法をカバーしています。\n",
    "\n",
    "第5章「ブール値インデックス作成」では、ブール値条件に基づいてデータのサブセットを選択するためにデータを照会するプロセスをカバーしています。\n",
    "\n",
    "第6章の「インデックスの整列」では、非常に重要で誤解されがちなインデックスオブジェクトを対象としています。インデックスの誤用は、多くの誤った結果の原因となります。これらのレシピでは、強力な結果を得るためにインデックスを正しく使用する方法を紹介します。\n",
    "\n",
    "第7章「集計、ろ過、および変換のためのグループ化」では、データ分析中にほぼ常に必要となる強力なグループ化機能を扱います。グループに適用するためのカスタマイズされた機能を構築します。\n",
    "\n",
    "第8章「データを整頓された形に再構築する」では、整頓されたデータとは何か、なぜ整頓されたデータが重要なのかを説明し、さまざまな形のごちゃごちゃしたデータセットを整頓されたデータに変換する方法を示しています。\n",
    "\n",
    "第9章「Pandasオブジェクトの結合」では、DataFramesとSeriesを縦または横に結合するための多くの利用可能なメソッドを扱います。また、トランプ大統領とオバマ大統領の支持率を比較するためのウェブスクレイピングを行い、SQLリレーショナルデータベースに接続します。\n",
    "\n",
    "第10章、時系列分析では、可能な限り時間の任意の次元で解剖するための高度で強力な時系列機能をカバーしています。\n",
    "\n",
    "第11章、Matplotlib、Pandas、Seabornを使った可視化では、pandasのすべてのプロットを担当しているmatplotlibライブラリを紹介します。次に、pandasのプロット方法、そして最後に、pandasでは直接利用できない美的に楽しいビジュアライゼーションを作成することができるseabornライブラリに焦点を移します。\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What you need for this book  \n",
    "\n",
    "Pandas is a third-party package for the Python programming language and, as of the printing of this book, is on version 0.20. Currently, Python has two major supported releases, versions 2.7 and 3.6. Python 3 is the future, and it is now highly recommended that all scientific computing users of Python use it, as Python 2 will no longer be supported in 2020. All examples in this book have been run and tested with pandas 0.20 on Python 3.6.  \n",
    "\n",
    "In addition to pandas, you will need to have the matplotlib version 2.0 and seaborn version 0.8 visualization libraries installed. A major dependence for pandas is the NumPy library, which forms the basis of most of the popular Python scientific computing libraries.\n",
    "\n",
    "There are a wide variety of ways in which you can install pandas and the rest of the libraries mentioned on your computer, but by far the simplest method is to install the Anaconda distribution. Created by Continuum Analytics, it packages together all the popular libraries for scientific computing in a single downloadable file available on Windows, Mac OSX, and Linux. Visit the download page to get the Anaconda distribution (https://www.anaconda.com/download).\n",
    "\n",
    "In addition to all the scientific computing libraries, the Anaconda distribution comes with Jupyter Notebook, which is a browser-based program for developing in Python, among many other languages. All of the recipes for this book were developed inside of a Jupyter Notebook and all of the individual notebooks for each chapter will be available for you to use.\n",
    "\n",
    "It is possible to install all the necessary libraries for this book without the use of the Anaconda distribution. For those that are interested, visit the pandas Installation page (http://pandas.pydata.org/pandas-docs/stable/install.html).\n",
    "\n",
    "PandasはPythonプログラミング言語のサードパーティ製パッケージで、本書の印刷時点ではバージョン0.20です。現在、Pythonはバージョン2.7と3.6の2つのメジャーリリースをサポートしています。Python 3は未来のものであり、2020年にはPython 2のサポートが終了するため、Pythonのすべての科学的コンピューティングユーザーがPythonを使用することが強く推奨されています。本書のすべての例は、Python 3.6上でpandas 0.20で実行・テストされています。 \n",
    "\n",
    "pandasに加えて、matplotlibバージョン2.0とseabornバージョン0.8の可視化ライブラリがインストールされている必要があります。pandasの主な依存物はNumPyライブラリであり、これはPythonの科学計算ライブラリのほとんどの基礎を形成しています。\n",
    "\n",
    "pandasやその他のライブラリをコンピュータにインストールする方法は多岐にわたりますが、最も簡単な方法はAnacondaディストリビューションをインストールすることです。Continuum Analyticsによって作成されたAnacondaは、科学的コンピューティングのためのすべての人気のあるライブラリを1つのダウンロード可能なファイルにまとめたもので、Windows、Mac OSX、Linuxで利用できます。Anacondaディストリビューションを入手するには、ダウンロードページにアクセスしてください（https://www.anaconda.com/download）。\n",
    "\n",
    "すべての科学計算ライブラリに加えて、Anaconda ディストリビューションには Jupyter Notebook が含まれています。これは、他の多くの言語の中でも Python で開発するためのブラウザベースのプログラムです。本書のレシピはすべて Jupyter Notebook の中で開発されており、各章の個別のノートはすべて利用可能です。\n",
    "\n",
    "この本に必要なすべてのライブラリをAnacondaディストリビューションを使わずにインストールすることが可能です。興味のある方は、pandasのインストールページ（http://pandas.pydata.org/pandas-docs/stable/install.html）をご覧ください。\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Who this book is for\n",
    "\n",
    "This book contains nearly 100 recipes, ranging from very simple to advanced. All recipes strive to be written in clear, concise, and modern idiomatic pandas code. The How it works... sections contain extremely detailed descriptions of the intricacies of each step of the recipe. Often, in the There's more... section, you will get what may seem like an entirely new recipe. This book is densely packed with an extraordinary amount of pandas code.\n",
    "\n",
    "As a generalization, the recipes in the first six chapters tend to be simpler and more focused on the fundamental and essential operations of pandas than the last five chapters, which focus on more advanced operations and are more project-driven. Due to the wide range of complexity, this book can be useful to both the novice and everyday user alike. It has been my experience that even those who use pandas regularly will not master it without being exposed to idiomatic pandas code. This is somewhat fostered by the breadth that pandas offers. There are almost always multiple ways of completing the same operation, which can have users get the result they want but in a very inefficient manner. It is not uncommon to see an order of magnitude or more performance difference between two sets of pandas solutions to the same problem.\n",
    "\n",
    "The only real prerequisite for this book is fundamental knowledge of Python. It is assumed that the reader is familiar with all the common built-in data containers in Python, such as lists, sets, dictionaries, and tuples.\n",
    "\n",
    "この本には、非常に簡単なものから上級者向けのものまで、100近くのレシピが掲載されています。すべてのレシピは、明確で、簡潔で、現代的な慣用的なパンダのコードで書かれるように努めています。How it works...のセクションでは、レシピの各ステップの複雑さを非常に詳細に説明しています。多くの場合、There's more...セクションでは、完全に新しいレシピのように見えるかもしれないものを得るでしょう。この本は、パンダのコードの異常な量で密に詰め込まれています。\n",
    "\n",
    "一般化すると、最初の6つの章のレシピは、より高度な操作に焦点を当て、よりプロジェクト主導型である最後の5つの章よりも、よりシンプルで、パンダの基本的で本質的な操作に焦点を当てている傾向があります。複雑さの幅が広いため、本書は初心者にも日常的なユーザーにも役立つ内容となっています。私の経験では、普段からパンダを使っている人でも、慣用的なパンダのコードに触れないと使いこなせないと思います。これはpandasが提供している幅の広さによって多少は助長されています。同じ操作を完了させるためには、ほとんどの場合、複数の方法が存在します。同じ問題に対する2つのパンダの解決策の間には、一桁以上の性能差があることも珍しくありません。\n",
    "\n",
    "本書の本当の前提条件は、Pythonの基本的な知識だけです。読者は、リスト、セット、辞書、タプルなど、Pythonに組み込まれた一般的なデータコンテナに精通していることが前提となっています。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to get the most out of this book\n",
    "\n",
    "There are a couple of things you can do to get the most out of this book. First, and most importantly, you should download all the code, which will be stored in Jupyter Notebooks. While reading through each recipe, run each step of code in the notebook. Make sure you explore on your own as you run through the code. Second, have the pandas official documentation open (http://pandas.pydata.org/pandas-docs/stable/) in one of your browser tabs. The pandas documentation is an excellent resource containing over 1,000 pages of material. There are examples for most of the pandas operations in the documentation, and they will often be directly linked from the See also section. While it covers the basics of most operations, it does so with trivial examples and fake data that don't reflect situations that you are likely to encounter when analyzing datasets from the real world.\n",
    "\n",
    "この本を最大限に活用するためにできることがいくつかあります。最初に、そして最も重要なことは、Jupyterノートブックに保存されるすべてのコードをダウンロードすることです。各レシピを読んでいる間に、ノートブック内のコードの各ステップを実行してください。コードを実行しながら、自分で探索することを確認してください。第二に、ブラウザのタブの一つでpandasの公式ドキュメント(http://pandas.pydata.org/pandas-docs/stable/)を開いてください。pandas のドキュメントは 1,000 ページ以上の資料を含む優れたリソースです。ドキュメントにはほとんどのpandas操作の例があり、See alsoセクションから直接リンクされていることが多いです。ほとんどの操作の基本をカバーしていますが、現実世界のデータセットを分析する際に遭遇するであろう状況を反映していない、些細な例やフェイクデータを使っています。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conventions\n",
    "\n",
    "In this book, you will find a few text styles that distinguish between different kinds of information. Most commonly you will see blocks of code during each recipe that will look like this:\n",
    "\n",
    "この本では、情報の異なる種類を区別するいくつかのテキストスタイルを見つけることができます。最も一般的には、このように見える各レシピの間にコードのブロックを見ることができます。\n",
    "\n",
    "```\n",
    ">>> employee = pd.read_csv('data/employee')\n",
    ">>> max_dept_salary = employee.groupby('DEPARTMENT')['BASE_SALARY'].max()\n",
    "```\n",
    "\n",
    "The pandas Series and DataFrames are stylized differently when output in the notebook. The pandas Series have no special formatting and are just raw text. They will appear directly preceding the line of code that creates them in the code block itself, like this:\n",
    "\n",
    "pandasシリーズとDataFramesは、ノートに出力するとスタイルが異なります。pandasシリーズには特別な書式設定はなく、ただの生のテキストです。それらは、コードブロック自体の中で、それらを作成するコードの行の直前に表示され、次のようになります。\n",
    "\n",
    "\n",
    "```\n",
    ">>> max_dept_salary.head()\n",
    "DEPARTMENT\n",
    "Admn. & Regulatory Affairs\n",
    "City Controller's Office\n",
    "City Council\n",
    "140416.0\n",
    " 64251.0\n",
    "100000.0\n",
    " 38397.0\n",
    " 89221.0\n",
    "Convention and Entertainment\n",
    "Dept of Neighborhoods (DON)\n",
    "Name: BASE_SALARY, dtype: float64\n",
    "```\n",
    "\n",
    "DataFrames, on the other hand, are nicely stylized in the notebooks and appear as images outside of the code box, like this:\n",
    "\n",
    "一方、データフレームは、ノートの中ではきれいにスタイル化されていて、コードボックスの外では、このように画像として表示されます。\n",
    "\n",
    "Code words in text, database table names, folder names, filenames, file extensions, pathnames, dummy URLs, user input, and Twitter handles are shown as follows: In order to find the average BASE_SALARY by GENDER, you can use the pivot_table method.　　\n",
    "\n",
    "テキスト内のコードワード、データベースのテーブル名、フォルダ名、ファイル名、ファイル拡張子、パス名、ダミーURL、ユーザー入力、Twitterハンドルは以下のように表示されます。GENDER別の平均的なBASE_SALARYを求めるには、pivot_tableを使用します。　　\n",
    "\n",
    "New terms and important words are shown in bold. Words that you see on the screen, for example, in menus or dialog boxes, appear in the text like this: \"In a Jupyter notebook, when holding down Shift + Tab + Tab with the cursor placed somewhere in the object, a window of the docsstrings will pop out making the method far easier to use.\"\n",
    "\n",
    "新しい用語や重要な単語は太字で表示されます。メニューやダイアログボックスなど、画面上で目にする単語は、このようにテキストに表示されます。\"Jupyter ノートブックでは、オブジェクトのどこかにカーソルを置いた状態で Shift + Tab + Tab を押し続けると、docsstrings のウィンドウが出てきて、この方法をはるかに使いやすくしてくれます。\"　　"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assumptions for every recipe\n",
    "\n",
    "すべてのレシピの前提条件\n",
    "\n",
    "It should be assumed that at the beginning of each recipe, pandas, NumPy, and matplotlib are imported into the namespace. For plots to be embedded directly within the notebook, you must also run the magic command %matplotlib inline. Also, all data is stored in the data directory and is most commonly stored as a CSV file, which can be read directly with the read_csv function.\n",
    "\n",
    "各レシピの最初に、pandas、NumPy、matplotlibが名前空間にインポートされていると仮定してください。プロットをノートブック内に直接埋め込むためには、マジックコマンド %matplotlib をインラインで実行する必要もあります。また、すべてのデータはデータ・ディレクトリに保存され、最も一般的にはCSVファイルとして保存され、read_csv関数で直接読み込むことができます。\n",
    "\n",
    "```\n",
    "   >>> import pandas as pd\n",
    "   >>> import numpy as np\n",
    "   >>> import matplotlib.pyplot as plt\n",
    "   >>> %matplotlib inline\n",
    "   >>> my_dataframe = pd.read_csv('data/dataset_name.csv')\n",
    "``` \n",
    "\n",
    "### Dataset Descriptions\n",
    "There are about two dozen datasets that are used throughout this book. It can be very helpful to have background information on each dataset as you complete the steps in the recipes. A detailed description of each dataset may be found in the dataset_descriptions Jupyter Notebook found at https://github.com/ PacktPublishing/Pandas-Cookbook. For each datastet, there will be a list of the columns, information about each column and notes on how the data was procured.\n",
    "\n",
    "この本の中で使われているデータセットは約2ダースあります。各データセットの背景情報があると、レシピのステップを完了する際に非常に役立ちます。各データセットの詳細な説明は、\n",
    "\n",
    "https://github.com/ PacktPublishing/Pandas-Cookbook\n",
    "\n",
    "にあるdataset_descriptions Jupyter Notebookにあります。各データセットについて、列のリスト、各列に関する情報、データの入手方法に関する注意事項が記載されています。\n",
    "\n",
    "### Sections\n",
    "In this book, you will find several headings that appear frequently (Getting ready, How to do it..., How it works..., There's more..., and See also).\n",
    "To give clear instructions on how to complete a recipe, we use these sections as follows:\n",
    "\n",
    "この本では、頻繁に表示されるいくつかの見出しを見つけることができます（準備中、どのようにそれを行うか...、どのように動作するか...、もっとあります...、および参照）。\n",
    "レシピを完成させる方法を明確に指示するために、次のようにこれらのセクションを使用しています。\n",
    "\n",
    "### Getting ready\n",
    "This section tells you what to expect in the recipe, and describes how to set up any software or any preliminary settings required for the recipe.\n",
    "\n",
    "このセクションでは、レシピで何を期待するかを説明し、レシピに必要な任意のソフトウェアまたは任意の予備設定を設定する方法を説明します。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
